{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/yandanw/.local/lib/python3.6/site-packages/ants/viz/render_surface_function.py:16: UserWarning:\n",
      "\n",
      "Cant import Plotly. Install it `pip install chart_studio` if you want to use ants.render_surface_function\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import brainsss\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import scipy\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "from scipy.cluster import hierarchy\n",
    "import matplotlib as mpl\n",
    "from matplotlib.pyplot import cm\n",
    "import random\n",
    "from scipy.stats import sem\n",
    "import time\n",
    "import h5py\n",
    "import ants\n",
    "import nibabel as nib\n",
    "\n",
    "import matplotlib\n",
    "from scipy.ndimage import gaussian_filter1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d as interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "func_path_1 = '/oak/stanford/groups/trc/data/Brezovec/2P_Imaging/20190101_walking_dataset/fly_261/func_0/'\n",
    "func_path_2 = '/oak/stanford/groups/trc/data/Brezovec/2P_Imaging/20190101_walking_dataset/fly_262/func_0/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flies_func_paths = [func_path_1,func_path_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_nav_neural_correlates(func_path):\n",
    "    ###########################\n",
    "    ### PREP VISUAL STIMULI ###\n",
    "    ###########################\n",
    "\n",
    "    vision_path = os.path.join(func_path, 'visual')\n",
    "    ### Load Photodiode ###\n",
    "    t, ft_triggers, pd1, pd2 = brainsss.load_photodiode(vision_path)\n",
    "    stimulus_start_times = brainsss.extract_stim_times_from_pd(pd2, t)\n",
    "    ### Unifrom the units and Make then intigers ###\n",
    "    stimulus_start_times = (stimulus_start_times*100).astype('int') #index needs to be an integers\n",
    "\n",
    "\n",
    "    ####################\n",
    "    ### Prep Fictrac ###\n",
    "    ####################\n",
    "\n",
    "    fictrac_path = os.path.join(func_path, 'fictrac')\n",
    "    fictrac_raw = brainsss.load_fictrac(fictrac_path)\n",
    "\n",
    "    fps = 100\n",
    "    resolution = 10 #desired resolution in ms\n",
    "    expt_len = fictrac_raw.shape[0]/fps*1000\n",
    "    behaviors = ['dRotLabY', 'dRotLabZ', 'heading']\n",
    "    fictrac = {}\n",
    "    for behavior in behaviors:\n",
    "        if behavior == 'dRotLabY': short = 'Y'\n",
    "        elif behavior == 'dRotLabZ': short = 'Z'\n",
    "        elif behavior == 'heading': short = 'h'\n",
    "        fictrac[short] = brainsss.smooth_and_interp_fictrac(fictrac_raw, fps, resolution, expt_len, behavior)\n",
    "        #fictrac[short] = np.roll(fictrac[short],400) # <------- misalignment is corrected !!!!!!\n",
    "    fictrac_timestamps = np.arange(0,expt_len,resolution)\n",
    "\n",
    "    fictrac['h'] = np.rad2deg(fictrac['h'])\n",
    "\n",
    "    def extract_traces(fictrac, stim_times, pre_window, post_window, behavior='Z'):\n",
    "        traces = []\n",
    "        for i in range(len(stim_times)):\n",
    "            trace = fictrac[behavior][stim_times[i]-pre_window:stim_times[i]+post_window]\n",
    "            if len(trace) == pre_window + post_window: # this handles fictrac that crashed or was aborted or some bullshit\n",
    "                traces.append(trace)\n",
    "        traces = np.asarray(traces)\n",
    "        mean_trace = np.mean(traces,axis=0)\n",
    "        sem_trace = scipy.stats.sem(traces,axis=0)\n",
    "        return traces, mean_trace, sem_trace\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    heading = fictrac['h']\n",
    "    heading = heading%360\n",
    "    \n",
    "    ##################################################################\n",
    "    ### Downsample the 100Hz fictrac data to 3384 neual data frame ###\n",
    "    ##################################################################\n",
    "    timestamps = brainsss.load_timestamps(os.path.join(func_path, 'imaging'))\n",
    "    fictrac_timestamps = np.arange(0,1800000,10)\n",
    "\n",
    "    def interpolate_to_neural(slice_num, timestamps):\n",
    "        x = timestamps[:, slice_num]\n",
    "        f = interp1d(fictrac_timestamps, heading, fill_value=\"extrapolate\") \n",
    "        ynew = f(x)\n",
    "        return ynew\n",
    "\n",
    "    fwd = fictrac['Y']\n",
    "    def interpolate_to_neural_fwd(slice_num, timestamps):\n",
    "        x = timestamps[:, slice_num]\n",
    "        f = interp1d(fictrac_timestamps, fwd, fill_value=\"extrapolate\") \n",
    "        ynew = f(x)\n",
    "        return ynew\n",
    "\n",
    "    ang = fictrac['Z']\n",
    "    def interpolate_to_neural_ang(slice_num, timestamps):\n",
    "        x = timestamps[:, slice_num]\n",
    "        f = interp1d(fictrac_timestamps, ang, fill_value=\"extrapolate\") \n",
    "        ynew = f(x)\n",
    "        return ynew\n",
    "\n",
    "    heading_interpolated = interpolate_to_neural(0,timestamps)\n",
    "    ### redefine 0\n",
    "    heading_interpolated -= 180\n",
    "    fwd_interpolated = interpolate_to_neural_fwd(0,timestamps)\n",
    "    ang_interpolated = interpolate_to_neural_ang(0,timestamps)\n",
    "    \n",
    "    neural_file = os.path.join(func_path, 'functional_channel_2_moco_zscore_highpass.h5') #\n",
    "    with h5py.File(neural_file, 'r') as h:\n",
    "        print(h['data'].shape)\n",
    "        neural = h['data'][:]\n",
    "        \n",
    "    # Define cluster boundaries\n",
    "    fixation_range = (-20, 20)\n",
    "    away_ranges = [(-180, -160), (160, 180)]\n",
    "    stop_fwd_threshold = 0.5\n",
    "    stop_ang_threshold = 10\n",
    "    # Initialize empty arrays for each cluster\n",
    "    fixation = []\n",
    "    away = []\n",
    "    rest = []\n",
    "    pause = []\n",
    "\n",
    "    # Loop through each angle and categorize it\n",
    "    for t, angle in enumerate(heading_interpolated.flatten()):\n",
    "        if angle >= fixation_range[0] and angle <= fixation_range[1]:\n",
    "            if np.abs(fwd_interpolated[t])>stop_fwd_threshold or np.abs(ang_interpolated[t])>stop_ang_threshold:\n",
    "                fixation.append(t)\n",
    "            else:\n",
    "                pause.append(t)\n",
    "        elif angle >= away_ranges[0][0] and angle <= away_ranges[0][1]:\n",
    "            if np.abs(fwd_interpolated[t])>stop_fwd_threshold or np.abs(ang_interpolated[t])>stop_ang_threshold:\n",
    "                away.append(t)\n",
    "            else:\n",
    "                pause.append(t)\n",
    "        elif angle >= away_ranges[1][0] and angle <= away_ranges[1][1]:\n",
    "            if np.abs(fwd_interpolated[t])>stop_fwd_threshold or np.abs(ang_interpolated[t])>stop_ang_threshold:\n",
    "                away.append(t)\n",
    "            else:\n",
    "                pause.append(t)\n",
    "        else:\n",
    "            rest.append(t)\n",
    "\n",
    "    # Print the number of angles in each cluster\n",
    "    # print(f\"Fixation: {len(fixation)}\")\n",
    "    # print(f\"Away: {len(away)}\")\n",
    "    # print(f\"Rest: {len(rest)}\")\n",
    "    # print(f\"Pause: {len(pause)}\")\n",
    "    # fixation, away, stop, and menotaxis are list of t (idex number in 3384)\n",
    "\n",
    "    pre_menotaxis = []\n",
    "    menotaxis = []\n",
    "    others = []\n",
    "    for t in rest:\n",
    "        if np.abs(fwd_interpolated[t])<stop_fwd_threshold and np.abs(ang_interpolated[t])<stop_ang_threshold:\n",
    "            pause.append(t)\n",
    "        else:\n",
    "            pre_menotaxis.append(t)\n",
    "    # print(f\"Pause: {len(pause)}\")\n",
    "    # print(f\"pre_menotaxis: {len(pre_menotaxis)}\")\n",
    "\n",
    "    pre_menotaxis_angles = [heading_interpolated.flatten()[t] for t in pre_menotaxis]\n",
    "    pre_menotaxis_angles = np.asarray(pre_menotaxis_angles)\n",
    "\n",
    "    for t, angle in enumerate(pre_menotaxis_angles.flatten()):\n",
    "        duration = pre_menotaxis_angles.flatten()[t:t+10] \n",
    "        # the fly needs to stabilize the bar within a range of 40 degrees for at least 5s, which is 10 imaging time units\n",
    "        if np.max(duration) - np.min(duration) <= 40:\n",
    "            menotaxis.append(t)\n",
    "        else:\n",
    "            others.append(t)\n",
    "    # print(f\"menotaxis: {len(menotaxis)}\")\n",
    "    # print(f\"others: {len(others)}\")\n",
    "\n",
    "    print(f\"Fixation: {len(fixation)}\")\n",
    "    print(f\"Away: {len(away)}\")\n",
    "    print(f\"Others: {len(others)}\")\n",
    "    print(f\"Pause: {len(pause)}\")\n",
    "    print(f\"Menotaxis: {len(menotaxis)}\")\n",
    "    print(f\"Sum: {len(fixation)+len(away)+len(others)+len(pause)+len(menotaxis)}\")\n",
    "    \n",
    "    nav_correlates = {'fix':neural[:,:,:,fixation], \n",
    "                      'escape':neural[:,:,:,away], \n",
    "                      'meno':neural[:,:,:,menotaxis], \n",
    "                      'pause':neural[:,:,:,pause], \n",
    "                      'other':neural[:,:,:,others]}\n",
    "    \n",
    "    return nav_correlates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading photodiode data... done\n",
      "Trying to load timestamp data from hdf5 file.\n",
      "Success.\n",
      "(256, 128, 49, 3384)\n",
      "Fixation: 264\n",
      "Away: 179\n",
      "Others: 1403\n",
      "Pause: 1189\n",
      "Menotaxis: 349\n",
      "Sum: 3384\n",
      "loading photodiode data... done\n",
      "Trying to load timestamp data from hdf5 file.\n",
      "Success.\n",
      "(256, 128, 49, 3384)\n",
      "Fixation: 342\n",
      "Away: 186\n",
      "Others: 2373\n",
      "Pause: 430\n",
      "Menotaxis: 53\n",
      "Sum: 3384\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all input arrays must have the same shape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-95d4a102d299>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mnav_correlates_all_flies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mnav_correlates_all_flies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fix'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnav_correlates_all_flies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fix'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mnav_correlates_all_flies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'escape'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnav_correlates_all_flies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'escape'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mnav_correlates_all_flies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'meno'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnav_correlates_all_flies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'meno'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out)\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'all input arrays must have the same shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0mresult_ndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all input arrays must have the same shape"
     ]
    }
   ],
   "source": [
    "nav_correlates_all_flies = {'fix':[], 'escape':[], 'meno':[], 'pause':[], 'other':[]}\n",
    "\n",
    "for func_path in flies_func_paths:\n",
    "    nav_correlates_fly = get_nav_neural_correlates(func_path)\n",
    "    for k,v in nav_correlates_fly.items():\n",
    "        nav_correlates_all_flies[k].append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nav_correlates_all_flies['fix'] = np.concatenate(nav_correlates_all_flies['fix'], axis=-1)    \n",
    "nav_correlates_all_flies['escape'] = np.concatenate(nav_correlates_all_flies['escape'], axis=-1)\n",
    "nav_correlates_all_flies['meno'] = np.concatenate(nav_correlates_all_flies['meno'], axis=-1)\n",
    "nav_correlates_all_flies['pause'] = np.concatenate(nav_correlates_all_flies['pause'], axis=-1)\n",
    "nav_correlates_all_flies['other'] = np.concatenate(nav_correlates_all_flies['other'], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(256, 128, 49, 264), (256, 128, 49, 342)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.shape for x in nav_correlates_all_flies['fix']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###########################\n",
    "### PREP VISUAL STIMULI ###\n",
    "###########################\n",
    "\n",
    "vision_path = os.path.join(func_path, 'visual')\n",
    "### Load Photodiode ###\n",
    "t, ft_triggers, pd1, pd2 = brainsss.load_photodiode(vision_path)\n",
    "stimulus_start_times = brainsss.extract_stim_times_from_pd(pd2, t)\n",
    "### Unifrom the units and Make then intigers ###\n",
    "stimulus_start_times = (stimulus_start_times*100).astype('int') #index needs to be an integers\n",
    "\n",
    "\n",
    "####################\n",
    "### Prep Fictrac ###\n",
    "####################\n",
    "\n",
    "fictrac_path = os.path.join(func_path, 'fictrac')\n",
    "fictrac_raw = brainsss.load_fictrac(fictrac_path)\n",
    "\n",
    "fps = 100\n",
    "resolution = 10 #desired resolution in ms\n",
    "expt_len = fictrac_raw.shape[0]/fps*1000\n",
    "behaviors = ['dRotLabY', 'dRotLabZ', 'heading']\n",
    "fictrac = {}\n",
    "for behavior in behaviors:\n",
    "    if behavior == 'dRotLabY': short = 'Y'\n",
    "    elif behavior == 'dRotLabZ': short = 'Z'\n",
    "    elif behavior == 'heading': short = 'h'\n",
    "    fictrac[short] = brainsss.smooth_and_interp_fictrac(fictrac_raw, fps, resolution, expt_len, behavior)\n",
    "    #fictrac[short] = np.roll(fictrac[short],400) # <------- misalignment is corrected !!!!!!\n",
    "fictrac_timestamps = np.arange(0,expt_len,resolution)\n",
    "\n",
    "fictrac['h'] = np.rad2deg(fictrac['h'])\n",
    "\n",
    "def extract_traces(fictrac, stim_times, pre_window, post_window, behavior='Z'):\n",
    "    traces = []\n",
    "    for i in range(len(stim_times)):\n",
    "        trace = fictrac[behavior][stim_times[i]-pre_window:stim_times[i]+post_window]\n",
    "        if len(trace) == pre_window + post_window: # this handles fictrac that crashed or was aborted or some bullshit\n",
    "            traces.append(trace)\n",
    "    traces = np.asarray(traces)\n",
    "    mean_trace = np.mean(traces,axis=0)\n",
    "    sem_trace = scipy.stats.sem(traces,axis=0)\n",
    "    return traces, mean_trace, sem_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "heading = fictrac['h']\n",
    "heading = heading%360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################################\n",
    "### Downsample the 100Hz fictrac data to 3384 neual data frame ###\n",
    "##################################################################\n",
    "timestamps = brainsss.load_timestamps(os.path.join(func_path, 'imaging'))\n",
    "fictrac_timestamps = np.arange(0,1800000,10)\n",
    "\n",
    "def interpolate_to_neural(slice_num, timestamps):\n",
    "    x = timestamps[:, slice_num]\n",
    "    f = interp1d(fictrac_timestamps, heading, fill_value=\"extrapolate\") \n",
    "    ynew = f(x)\n",
    "    return ynew\n",
    "\n",
    "fwd = fictrac['Y']\n",
    "def interpolate_to_neural_fwd(slice_num, timestamps):\n",
    "    x = timestamps[:, slice_num]\n",
    "    f = interp1d(fictrac_timestamps, fwd, fill_value=\"extrapolate\") \n",
    "    ynew = f(x)\n",
    "    return ynew\n",
    "\n",
    "ang = fictrac['Z']\n",
    "def interpolate_to_neural_ang(slice_num, timestamps):\n",
    "    x = timestamps[:, slice_num]\n",
    "    f = interp1d(fictrac_timestamps, ang, fill_value=\"extrapolate\") \n",
    "    ynew = f(x)\n",
    "    return ynew\n",
    "\n",
    "heading_interpolated = interpolate_to_neural(0,timestamps)\n",
    "### redefine 0\n",
    "heading_interpolated -= 180\n",
    "fwd_interpolated = interpolate_to_neural_fwd(0,timestamps)\n",
    "ang_interpolated = interpolate_to_neural_ang(0,timestamps)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neural_file = os.path.join(func_path, 'functional_channel_2_moco_zscore_highpass.h5') #\n",
    "with h5py.File(neural_file, 'r') as h:\n",
    "    print(h['data'].shape)\n",
    "    neural = h['data'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixation: 342\n",
      "Away: 186\n",
      "Others: 2373\n",
      "Pause: 430\n",
      "Menotaxis: 53\n",
      "Sum: 3384\n"
     ]
    }
   ],
   "source": [
    "# Define cluster boundaries\n",
    "fixation_range = (-20, 20)\n",
    "away_ranges = [(-180, -160), (160, 180)]\n",
    "stop_fwd_threshold = 0.5\n",
    "stop_ang_threshold = 10\n",
    "\n",
    "# Initialize empty arrays for each cluster\n",
    "fixation = []\n",
    "away = []\n",
    "rest = []\n",
    "pause = []\n",
    "\n",
    "# Loop through each angle and categorize it\n",
    "for t, angle in enumerate(heading_interpolated.flatten()):\n",
    "    if angle >= fixation_range[0] and angle <= fixation_range[1]:\n",
    "        if np.abs(fwd_interpolated[t])>stop_fwd_threshold or np.abs(ang_interpolated[t])>stop_ang_threshold:\n",
    "            fixation.append(t)\n",
    "        else:\n",
    "            pause.append(t)\n",
    "    elif angle >= away_ranges[0][0] and angle <= away_ranges[0][1]:\n",
    "        if np.abs(fwd_interpolated[t])>stop_fwd_threshold or np.abs(ang_interpolated[t])>stop_ang_threshold:\n",
    "            away.append(t)\n",
    "        else:\n",
    "            pause.append(t)\n",
    "    elif angle >= away_ranges[1][0] and angle <= away_ranges[1][1]:\n",
    "        if np.abs(fwd_interpolated[t])>stop_fwd_threshold or np.abs(ang_interpolated[t])>stop_ang_threshold:\n",
    "            away.append(t)\n",
    "        else:\n",
    "            pause.append(t)\n",
    "    else:\n",
    "        rest.append(t)\n",
    "\n",
    "# Print the number of angles in each cluster\n",
    "# print(f\"Fixation: {len(fixation)}\")\n",
    "# print(f\"Away: {len(away)}\")\n",
    "# print(f\"Rest: {len(rest)}\")\n",
    "# print(f\"Pause: {len(pause)}\")\n",
    "# fixation, away, stop, and menotaxis are list of t (idex number in 3384)\n",
    "\n",
    "pre_menotaxis = []\n",
    "menotaxis = []\n",
    "others = []\n",
    "for t in rest:\n",
    "    if np.abs(fwd_interpolated[t])<stop_fwd_threshold and np.abs(ang_interpolated[t])<stop_ang_threshold:\n",
    "        pause.append(t)\n",
    "    else:\n",
    "        pre_menotaxis.append(t)\n",
    "# print(f\"Pause: {len(pause)}\")\n",
    "# print(f\"pre_menotaxis: {len(pre_menotaxis)}\")\n",
    "\n",
    "pre_menotaxis_angles = [heading_interpolated.flatten()[t] for t in pre_menotaxis]\n",
    "pre_menotaxis_angles = np.asarray(pre_menotaxis_angles)\n",
    "\n",
    "for t, angle in enumerate(pre_menotaxis_angles.flatten()):\n",
    "    duration = pre_menotaxis_angles.flatten()[t:t+10] \n",
    "    # the fly needs to stabilize the bar within a range of 40 degrees for at least 5s, which is 10 imaging time units\n",
    "    if np.max(duration) - np.min(duration) <= 40:\n",
    "        menotaxis.append(t)\n",
    "    else:\n",
    "        others.append(t)\n",
    "# print(f\"menotaxis: {len(menotaxis)}\")\n",
    "# print(f\"others: {len(others)}\")\n",
    "\n",
    "print(f\"Fixation: {len(fixation)}\")\n",
    "print(f\"Away: {len(away)}\")\n",
    "print(f\"Others: {len(others)}\")\n",
    "print(f\"Pause: {len(pause)}\")\n",
    "print(f\"Menotaxis: {len(menotaxis)}\")\n",
    "print(f\"Sum: {len(fixation)+len(away)+len(others)+len(pause)+len(menotaxis)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nav_correlates = {'fix':[], 'escape':[], 'meno':[], 'pause':[], 'other':[]}\n",
    "for f in flies:\n",
    "    fix = f.neural[:,:,:,fixation]\n",
    "    nav_correlates.['fix'].append(fix)\n",
    "    escape = f.neural[:,:,:,away]\n",
    "    nav_correlates.['escape'].append(escape)\n",
    "    meno = f.neural[:,:,:,menotaxis]\n",
    "    nav_correlates.['meno'].append(meno)\n",
    "    pause = f.neural[:,:,:,pause]\n",
    "    nav_correlates.['pause'].append(pause)\n",
    "    other = f.neural[:,:,:,others]\n",
    "    nav_correlates.['other'].append(other)\n",
    "nav_correlates['fix'] = np.stack(nav_correlates['fix'], axis=-1)    \n",
    "nav_correlates['escape'] = np.stack(nav_correlates['escape'], axis=-1)\n",
    "nav_correlates['meno'] = np.stack(nav_correlates['meno'], axis=-1)\n",
    "nav_correlates['pause'] = np.stack(nav_correlates['pause'], axis=-1)\n",
    "nav_correlates['other'] = np.stack(nav_correlates['other'], axis=-1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####### Explode the brain #############\n",
    "all_explosions = {}\n",
    "for condition in ['ve_no_0','ve_no_180','ve_0','ve_180']:\n",
    "    print(condition)\n",
    "    \n",
    "    if '180' in condition:\n",
    "        angle = 180\n",
    "    else:\n",
    "        angle = 0\n",
    "    if 'no' in condition:\n",
    "        event_times_list = ve_no_turn_times[angle]\n",
    "    else:\n",
    "        event_times_list = ve_turn_times[angle]\n",
    "    \n",
    "    t0 = time.time()\n",
    "    STA_brain = brainsss.make_STA_brain(neural_signals = all_signals,\n",
    "                                       neural_timestamps = timestamps,\n",
    "                                       event_times_list = event_times_list,\n",
    "                                       neural_bins = neural_bins)\n",
    "    print(F'STA {time.time()-t0}')\n",
    "\n",
    "    reformed_STA_brain = brainsss.STA_supervoxel_to_full_res(STA_brain, cluster_labels)\n",
    "    STA_brain = gaussian_filter1d(reformed_STA_brain,sigma=1,axis=1,truncate=1)\n",
    "    \n",
    "    \n",
    "    t0 = time.time()\n",
    "    warps = brainsss.warp_STA_brain(STA_brain=STA_brain, fly='fly_134', fixed=fixed, anat_to_mean_type='myr')\n",
    "    print(F'Warps {time.time()-t0}')\n",
    "    \n",
    "    explosions = []\n",
    "    t0 = time.time()\n",
    "    for tp in range(24):\n",
    "        input_canvas = np.ones((500,500,3)) #+.5 #.5 for diverging\n",
    "        data_to_plot = warps[tp][:,:,::-1]\n",
    "        vmax = 0.5\n",
    "        explosion_map = brainsss.place_roi_groups_on_canvas(explosion_rois,\n",
    "                                                            roi_masks,\n",
    "                                                            roi_contours,\n",
    "                                                            data_to_plot,\n",
    "                                                            input_canvas,\n",
    "                                                            vmax=vmax,\n",
    "                                                            cmap='seismic',\n",
    "                                                           diverging=True)#'hot')\n",
    "        explosions.append(explosion_map)\n",
    "    print(F'Explosion {time.time()-t0}')\n",
    "    all_explosions[condition] = explosions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
