{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/yandanw/.local/lib/python3.6/site-packages/ants/viz/render_surface_function.py:16: UserWarning:\n",
      "\n",
      "Cant import Plotly. Install it `pip install chart_studio` if you want to use ants.render_surface_function\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import brainsss\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import scipy\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "from scipy.cluster import hierarchy\n",
    "import matplotlib as mpl\n",
    "from matplotlib.pyplot import cm\n",
    "import random\n",
    "from scipy.stats import sem\n",
    "import time\n",
    "import h5py\n",
    "import ants\n",
    "import nibabel as nib\n",
    "\n",
    "import matplotlib\n",
    "from scipy.ndimage import gaussian_filter1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "import sys\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "import pandas as pd\n",
    "import psutil\n",
    "#from tqdm import tqdm\n",
    "sys.path.insert(0, '/home/users/brezovec/.local/lib/python3.6/site-packages/lib/python/')\n",
    "import ants\n",
    "#import bigbadbrain as bbb\n",
    "from scipy.linalg import toeplitz\n",
    "import scipy.linalg as sl\n",
    "from scipy.signal import convolve2d\n",
    "from scipy.signal import convolve\n",
    "from sklearn.linear_model import LassoLarsIC\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d as interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "func_path = '/oak/stanford/groups/trc/data/Brezovec/2P_Imaging/20190101_walking_dataset/fly_261/func_0/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading photodiode data... done\n"
     ]
    }
   ],
   "source": [
    "###########################\n",
    "### PREP VISUAL STIMULI ###\n",
    "###########################\n",
    "\n",
    "vision_path = os.path.join(func_path, 'visual')\n",
    "### Load Photodiode ###\n",
    "t, ft_triggers, pd1, pd2 = brainsss.load_photodiode(vision_path)\n",
    "stimulus_start_times = brainsss.extract_stim_times_from_pd(pd2, t)\n",
    "### Unifrom the units and Make then intigers ###\n",
    "stimulus_start_times = (stimulus_start_times*100).astype('int') #index needs to be an integers\n",
    "\n",
    "\n",
    "####################\n",
    "### Prep Fictrac ###\n",
    "####################\n",
    "\n",
    "fictrac_path = os.path.join(func_path, 'fictrac')\n",
    "fictrac_raw = brainsss.load_fictrac(fictrac_path)\n",
    "\n",
    "fps = 100\n",
    "resolution = 10 #desired resolution in ms\n",
    "expt_len = fictrac_raw.shape[0]/fps*1000\n",
    "behaviors = ['dRotLabY', 'dRotLabZ', 'heading']\n",
    "fictrac = {}\n",
    "for behavior in behaviors:\n",
    "    if behavior == 'dRotLabY': short = 'Y'\n",
    "    elif behavior == 'dRotLabZ': short = 'Z'\n",
    "    elif behavior == 'heading': short = 'h'\n",
    "    fictrac[short] = brainsss.smooth_and_interp_fictrac(fictrac_raw, fps, resolution, expt_len, behavior)\n",
    "    #fictrac[short] = np.roll(fictrac[short],400) # <------- misalignment is corrected !!!!!!\n",
    "fictrac_timestamps = np.arange(0,expt_len,resolution)\n",
    "\n",
    "fictrac['h'] = np.rad2deg(fictrac['h'])\n",
    "\n",
    "def extract_traces(fictrac, stim_times, pre_window, post_window, behavior='Z'):\n",
    "    traces = []\n",
    "    for i in range(len(stim_times)):\n",
    "        trace = fictrac[behavior][stim_times[i]-pre_window:stim_times[i]+post_window]\n",
    "        if len(trace) == pre_window + post_window: # this handles fictrac that crashed or was aborted or some bullshit\n",
    "            traces.append(trace)\n",
    "    traces = np.asarray(traces)\n",
    "    mean_trace = np.mean(traces,axis=0)\n",
    "    sem_trace = scipy.stats.sem(traces,axis=0)\n",
    "    return traces, mean_trace, sem_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 128, 49, 3384)\n"
     ]
    }
   ],
   "source": [
    "#######################\n",
    "### Load Neural Data###\n",
    "#######################\n",
    "neural_file = os.path.join(func_path, 'functional_channel_2_moco_zscore_highpass.h5') #\n",
    "with h5py.File(neural_file, 'r') as h:\n",
    "    print(h['data'].shape)\n",
    "    neural = h['data'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49, 2000, 3384)\n"
     ]
    }
   ],
   "source": [
    "#################\n",
    "### Supervox ###\n",
    "#################\n",
    "n_clusters = 2000\n",
    "cluster_dir = os.path.join(func_path, 'clustering')\n",
    "\n",
    "load_file = os.path.join(cluster_dir, 'cluster_labels.npy')\n",
    "cluster_labels = np.load(load_file)\n",
    "\n",
    "load_file = os.path.join(cluster_dir, 'cluster_signals.npy')\n",
    "all_signals = np.load(load_file)\n",
    "print(all_signals.shape)\n",
    "# all_signals -> analysis -> supervoxel_to_full_rex -> exploded brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to load timestamp data from hdf5 file.\n",
      "Success.\n"
     ]
    }
   ],
   "source": [
    "#################\n",
    "### Supervox ###\n",
    "#################\n",
    "all_signals.shape\n",
    "\n",
    "timestamps = brainsss.load_timestamps(os.path.join(func_path, 'imaging'))\n",
    "\n",
    "fixed = brainsss.load_fda_meanbrain()\n",
    "\n",
    "atlas = brainsss.load_roi_atlas()\n",
    "\n",
    "explosion_rois = brainsss.load_explosion_groups()\n",
    "all_rois = brainsss.unnest_roi_groups(explosion_rois)\n",
    "roi_masks = brainsss.make_single_roi_masks(all_rois, atlas)\n",
    "roi_contours = brainsss.make_single_roi_contours(roi_masks, atlas)\n",
    "\n",
    "def supervoxel_to_full_res(brain, cluster_labels):\n",
    "    n_clusters = brain.shape[1]\n",
    "    \n",
    "    reformed_brain = []\n",
    "    for z in range(49):\n",
    "        colored_by_betas = np.zeros((256*128))\n",
    "        for cluster_num in range(n_clusters):\n",
    "            cluster_indicies = np.where(cluster_labels[z,:]==cluster_num)[0]\n",
    "            colored_by_betas[cluster_indicies] = brain[z,cluster_num]\n",
    "        colored_by_betas = colored_by_betas.reshape(256,128)\n",
    "        reformed_brain.append(colored_by_betas)\n",
    "    return np.asarray(reformed_brain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "heading = fictrac['h']\n",
    "heading = heading%360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to load timestamp data from hdf5 file.\n",
      "Success.\n"
     ]
    }
   ],
   "source": [
    "##################################################################\n",
    "### Downsample the 100Hz fictrac data to 3384 neual data frame ###\n",
    "##################################################################\n",
    "timestamps = brainsss.load_timestamps(os.path.join(func_path, 'imaging'))\n",
    "fictrac_timestamps = np.arange(0,1800000,10)\n",
    "\n",
    "def interpolate_to_neural(slice_num, timestamps):\n",
    "    x = timestamps[:, slice_num]\n",
    "    f = interp1d(fictrac_timestamps, heading, fill_value=\"extrapolate\") \n",
    "    ynew = f(x)\n",
    "    return ynew\n",
    "\n",
    "fwd = fictrac['Y']\n",
    "def interpolate_to_neural_fwd(slice_num, timestamps):\n",
    "    x = timestamps[:, slice_num]\n",
    "    f = interp1d(fictrac_timestamps, fwd, fill_value=\"extrapolate\") \n",
    "    ynew = f(x)\n",
    "    return ynew\n",
    "\n",
    "ang = fictrac['Z']\n",
    "def interpolate_to_neural_ang(slice_num, timestamps):\n",
    "    x = timestamps[:, slice_num]\n",
    "    f = interp1d(fictrac_timestamps, ang, fill_value=\"extrapolate\") \n",
    "    ynew = f(x)\n",
    "    return ynew\n",
    "\n",
    "heading_interpolated = interpolate_to_neural(0,timestamps)\n",
    "### redefine 0\n",
    "heading_interpolated -= 180\n",
    "fwd_interpolated = interpolate_to_neural_fwd(0,timestamps)\n",
    "ang_interpolated = interpolate_to_neural_ang(0,timestamps)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixation: 125\n",
      "Away: 68\n",
      "Menotaxis: 189\n",
      "Pause: 1189\n",
      "Others: 953\n",
      "Sum: 2524\n"
     ]
    }
   ],
   "source": [
    "# Define cluster boundaries\n",
    "fixation_range = [(0,20),(340,360)]\n",
    "away_ranges = [(160, 220)]\n",
    "stop_fwd_threshold = 0.5\n",
    "stop_ang_threshold = 10\n",
    "\n",
    "# Initialize empty arrays for each cluster\n",
    "# pre_fixation = []\n",
    "fixation =[]\n",
    "# pre_away =[]\n",
    "away = []\n",
    "rest = []\n",
    "pause = []\n",
    "others = []\n",
    "pause1 =[]\n",
    "\n",
    "# Loop through each angle and categorize it\n",
    "for t, angle in enumerate(heading_interpolated.flatten()):\n",
    "    if angle >= 160 and angle <= 220:\n",
    "        if np.abs(fwd_interpolated[t])>stop_fwd_threshold or np.abs(ang_interpolated[t])>stop_ang_threshold:\n",
    "            away.append(t)\n",
    "        else:\n",
    "            pause.append(t)            \n",
    "    elif angle >= 0 and angle <= 20:\n",
    "        if np.abs(fwd_interpolated[t])>stop_fwd_threshold or np.abs(ang_interpolated[t])>stop_ang_threshold:\n",
    "            fixation.append(t)\n",
    "        else:\n",
    "            pause.append(t)\n",
    "    elif angle >= 340 and angle <= 360:\n",
    "        if np.abs(fwd_interpolated[t])>stop_fwd_threshold or np.abs(ang_interpolated[t])>stop_ang_threshold:\n",
    "            fixation.append(t)\n",
    "        else:\n",
    "            pause.append(t)\n",
    "    else:\n",
    "        rest.append(t)\n",
    "\n",
    "# pre_fixation_angles = [heading_interpolated.flatten()[t] for t in pre_fixation]\n",
    "# pre_fixation_angles = np.asarray(pre_fixation_angles)\n",
    "\n",
    "\n",
    "# for t in pre_fixation:\n",
    "#     duration = heading_interpolated[pre_fixation[t:t+1]]\n",
    "#     if duration.size > 0:\n",
    "#         if np.max(duration) - np.min(duration) <= 40:\n",
    "#             fixation.append(t)\n",
    "#         else:\n",
    "#             others.append(t) \n",
    "# for t in pre_away:\n",
    "#     duration = heading_interpolated[pre_away[t:t+1]]\n",
    "#     if duration.size > 0:\n",
    "#         if np.max(duration) - np.min(duration) <= 40:\n",
    "#             away.append(t)\n",
    "#         else:\n",
    "#             others.append(t) \n",
    "\n",
    "pre_menotaxis = []\n",
    "menotaxis = []\n",
    "\n",
    "for t in rest:\n",
    "    if np.abs(fwd_interpolated[t])<stop_fwd_threshold and np.abs(ang_interpolated[t])<stop_ang_threshold:\n",
    "        pause.append(t)\n",
    "    else:\n",
    "        pre_menotaxis.append(t)\n",
    "        \n",
    "for t in pre_menotaxis:\n",
    "    duration = heading_interpolated[pre_menotaxis[t:t+10]]\n",
    "    if duration.size > 0:\n",
    "        if np.max(duration) - np.min(duration) <= 40:\n",
    "            menotaxis.append(t)\n",
    "        else:\n",
    "            others.append(t)\n",
    "\n",
    "\n",
    "print(f\"Fixation: {len(fixation)}\")\n",
    "print(f\"Away: {len(away)}\")\n",
    "print(f\"Menotaxis: {len(menotaxis)}\")\n",
    "print(f\"Pause: {len(pause)}\")\n",
    "\n",
    "print(f\"Others: {len(others)}\")\n",
    "print(f\"Sum: {len(fixation)+len(away)+len(others)+len(pause)+len(menotaxis)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum: 3384\n"
     ]
    }
   ],
   "source": [
    "print(f\"Sum: {len(fixation)+len(away)+len(rest)+len(pause1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rest: 2002\n"
     ]
    }
   ],
   "source": [
    "print(f\"rest: {len(pre_menotaxis)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum: 1142\n"
     ]
    }
   ],
   "source": [
    "print(f\"Sum: {len(others)+len(menotaxis)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sleep: 2\n"
     ]
    }
   ],
   "source": [
    "sleep = []\n",
    "for t in pause:\n",
    "    fwd_d = fwd_interpolated[t:t+30]\n",
    "    ang_d = np.unwrap(ang_interpolated[t:t+30])\n",
    "    if np.max(fwd_d)-np.min(fwd_d) < stop_fwd_threshold and np.max(ang_d)-np.min(ang_d) < stop_ang_threshold:\n",
    "        sleep.append(t)\n",
    "    else:\n",
    "        others.append(t)\n",
    "print(f\"Sleep: {len(sleep)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fixation_neural = neural[:,:,:,fixation]\n",
    "away_neural = neural[:,:,:,away]\n",
    "meno_neural = neural[:,:,:,menotaxis]\n",
    "sleep_neural = neural[:,:,:,sleep]\n",
    "pause_neural = neural[:,:,:,pause]\n",
    "others_neural = neural[:,:,:,others]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "atlas = brainsss.load_roi_atlas()\n",
    "\n",
    "explosion_rois = brainsss.load_explosion_groups()\n",
    "all_rois = brainsss.unnest_roi_groups(explosion_rois)\n",
    "roi_masks = brainsss.make_single_roi_masks(all_rois, atlas)\n",
    "roi_contours = brainsss.make_single_roi_contours(roi_masks, atlas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 1189, 256, 128)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = np.rollaxis(pause_neural,3,0)\n",
    "out = np.rollaxis(out,3,0)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "warp= brainsss.warp_STA_brain(out, fly = \"fly_262\", fixed=fixed, anat_to_mean_type = \"myr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fly_path='/oak/stanford/groups/trc/data/Brezovec/2P_Imaging/20190101_walking_dataset/fly_262/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.mkdir(os.path.join(fly_path,'analysis'))\n",
    "savefile = os.path.join(fly_path,'analysis',\"20230517_warp_pause\")\n",
    "np.save(savefile,warp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
